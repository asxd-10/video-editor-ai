# Analysis Workflow - Complete Guide

## ðŸ”„ What Happens When You Click "Analyze"

### **1. API Request Flow**

```
Frontend â†’ POST /api/videos/{video_id}/analyze
         â†“
Backend API (edit.py) â†’ Checks if already analyzed
         â†“
         â†’ Queues Celery task: analyze_video_task.delay(video_id)
         â†“
         â†’ Returns: {status: "queued", task_id: "..."}
```

### **2. Background Task Execution (Celery Worker)**

```
Celery Worker receives task
         â†“
analyze_video_task(video_id)
         â†“
1. Loads video from database
2. Extracts audio from video (using TranscriptionService)
3. Calls AnalysisService.analyze_video()
         â†“
AnalysisService runs:
  a) detect_silence(audio_path) â†’ Silence segments
  b) detect_scenes(video_path) â†’ Scene timestamps
         â†“
Stores result in: video.analysis_metadata
         â†“
Database updated: analysis_metadata = {
  "silence_segments": [(start, end), ...],
  "scene_timestamps": [timestamp1, timestamp2, ...]
}
```

---

## ðŸ“š External Libraries Used

### **1. Silence Detection**

#### **Primary: `silero-vad`**
- **What it is:** AI-powered Voice Activity Detection (VAD) model
- **How it works:**
  - Uses PyTorch neural network to detect speech vs silence
  - Analyzes audio waveform to identify speech segments
  - Returns timestamps of when speech occurs
  - We invert this to get silence segments
- **Dependencies:**
  - `torch` (PyTorch) - CPU-only version
  - `torchaudio` - Audio loading/processing
- **Cost:** FREE (open-source, runs locally)
- **Accuracy:** High (AI-based, better than energy-based methods)

#### **Fallback: `pydub`**
- **What it is:** Audio manipulation library
- **How it works:**
  - Analyzes audio energy levels (dBFS)
  - If energy < -40 dBFS â†’ considered silence
  - Checks every 100ms chunk
- **When used:** If `silero-vad` fails to load
- **Accuracy:** Lower (simple energy threshold)

### **2. Scene Detection**

#### **Library: `scenedetect[opencv]`**
- **What it is:** PySceneDetect - Scene change detection
- **How it works:**
  - Uses `ContentDetector` algorithm
  - Compares consecutive video frames
  - Detects significant visual changes (scene cuts)
  - Returns timestamps of scene changes
- **Dependencies:**
  - `opencv-python` (via `scenedetect[opencv]`)
  - FFmpeg (system dependency)
- **Cost:** FREE (open-source)
- **Accuracy:** Good for obvious scene cuts

### **3. Audio Extraction**

#### **Library: `ffmpeg-python`**
- **What it is:** Python wrapper for FFmpeg
- **How it works:**
  - Extracts audio track from video file
  - Converts to WAV format for analysis
  - Stored temporarily in `storage/temp/`
- **Cost:** FREE (FFmpeg is open-source)

---

## ðŸŽ¯ Which Edits Require Analysis?

### **âœ… REQUIRES Analysis:**

1. **Remove Silence** (`remove_silence: true`)
   - **Requires:** `analysis_metadata.silence_segments`
   - **Why:** Needs to know which segments are silence to remove them
   - **What happens without it:** 
     - If `analysis_metadata` is null â†’ No silence removal (just aspect ratio conversion)
     - If `silence_segments` is empty â†’ No silences detected, full video kept

2. **Scene-Based Editing** (Future feature)
   - **Requires:** `analysis_metadata.scene_timestamps`
   - **Why:** To make cuts at scene boundaries
   - **Status:** Not yet implemented

### **âŒ DOES NOT Require Analysis:**

1. **Aspect Ratio Conversion** (9:16, 1:1, 16:9)
   - **Independent:** Works on any video
   - **No analysis needed**

2. **Jump Cuts** (`jump_cuts: true`)
   - **Requires:** Transcript (not analysis)
   - **Uses:** Word-level timestamps from transcription

3. **Auto Captions** (`captions: true`)
   - **Requires:** Transcript (not analysis)
   - **Uses:** Transcript segments for subtitle timing

4. **Dynamic Zoom** (`dynamic_zoom: true`)
   - **Requires:** Face detection (MediaPipe) - not analysis
   - **Status:** Placeholder (not fully implemented)

5. **Pace Optimization** (`pace_optimize: true`)
   - **Requires:** Transcript + audio analysis (future)
   - **Status:** Placeholder (not fully implemented)

---

## ðŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Clicks    â”‚
â”‚  "Analyze"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Endpoint   â”‚
â”‚  /analyze       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Celery Queue   â”‚â”€â”€â”€â”€â”€â–¶â”‚  Worker Process  â”‚
â”‚  (Redis)        â”‚      â”‚  (Background)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Extract Audio    â”‚
                         â”‚ (FFmpeg)         â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                           â”‚
                    â–¼                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Silence Detectionâ”‚      â”‚ Scene Detection  â”‚
         â”‚ (silero-vad)     â”‚      â”‚ (scenedetect)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                         â”‚
                  â”‚ [(0.0, 2.5), ...]       â”‚ [10.5, 25.3, ...]
                  â”‚                         â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Store in Databaseâ”‚
                    â”‚ analysis_metadataâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¾ Data Storage

### **Database Schema:**
```python
video.analysis_metadata = {
    "silence_segments": [
        (0.0, 2.5),      # Silence from 0s to 2.5s
        (15.3, 16.8),   # Silence from 15.3s to 16.8s
        (45.0, 47.2)    # Silence from 45s to 47.2s
    ],
    "scene_timestamps": [
        10.5,   # Scene change at 10.5s
        25.3,   # Scene change at 25.3s
        40.1    # Scene change at 40.1s
    ]
}
```

### **Storage Location:**
- **Database:** `videos.analysis_metadata` (JSON column in PostgreSQL)
- **Temporary Files:** `storage/temp/{video_id}/audio.wav` (deleted after analysis)

---

## âš™ï¸ Configuration & Parameters

### **Silence Detection:**
- **Min Silence Duration:** 600ms (0.6 seconds)
  - Only silences longer than this are detected
  - Shorter pauses are ignored (considered part of speech)
- **VAD Threshold:** 0.5 (for silero-vad)
  - Higher = more strict (fewer false positives)
  - Lower = more lenient (more false negatives)

### **Scene Detection:**
- **Threshold:** 30.0 (default)
  - Higher = fewer scene changes detected (only major cuts)
  - Lower = more scene changes (sensitive to any change)

---

## ðŸ” How Editing Uses Analysis Data

### **Example: Remove Silence**

```python
# 1. Load analysis data
silence_segments = video.analysis_metadata["silence_segments"]
# â†’ [(0.0, 2.5), (15.3, 16.8)]

# 2. Build Edit Decision List (EDL)
edl = [
    {"start": 2.5, "end": 15.3, "type": "keep"},   # Keep speech
    {"start": 15.3, "end": 16.8, "type": "skip"},  # Skip silence
    {"start": 16.8, "end": 60.0, "type": "keep"}   # Keep speech
]

# 3. FFmpeg extracts only "keep" segments
# 4. Concatenates them into final video
# Result: Video with silences removed
```

---

## ðŸš¨ Error Handling

### **If Analysis Fails:**
1. **Silero VAD fails to load:**
   - Falls back to `pydub` energy-based detection
   - Logs warning but continues

2. **Scene detection fails:**
   - Returns empty list `[]`
   - Analysis still completes (silence detection works)

3. **Audio extraction fails:**
   - Task retries (Celery retry mechanism)
   - Max 3 retries with 60s delay

### **If Analysis Not Run:**
- **Remove Silence:** Works but finds no silences â†’ keeps full video
- **Scene-based edits:** Not available (requires scene_timestamps)

---

## ðŸ“ˆ Performance

### **Typical Processing Times:**
- **Audio Extraction:** 5-10 seconds (depends on video length)
- **Silence Detection:** 10-30 seconds (depends on audio length)
- **Scene Detection:** 20-60 seconds (depends on video length)
- **Total:** ~1-2 minutes for a 10-minute video

### **Resource Usage:**
- **CPU:** High (AI model inference)
- **Memory:** ~500MB-1GB (PyTorch model)
- **Disk:** Temporary audio file (~10-50MB)

---

## ðŸŽ“ Summary

**Analysis is required for:**
- âœ… Remove Silence feature
- âœ… Future scene-based editing

**Analysis is NOT required for:**
- âŒ Aspect ratio conversion
- âŒ Jump cuts (needs transcript)
- âŒ Captions (needs transcript)
- âŒ Basic video editing

**Libraries Used:**
- `silero-vad` - AI silence detection (FREE, local)
- `scenedetect` - Scene change detection (FREE, local)
- `ffmpeg-python` - Audio extraction (FREE, local)
- `pydub` - Fallback silence detection (FREE, local)

**All analysis runs locally - no API costs!**



# What "Analysis Complete" Means for Users

## ðŸŽ¯ User Value Proposition

When analysis is complete, users get:

### **1. Visual Insights Card**
- **Silence Statistics:**
  - Number of silence segments detected
  - Total silence time (e.g., "2m 15s")
  - Percentage of video that's silence (e.g., "15.3%")
- **Scene Statistics:**
  - Number of scene changes detected
  - Visual indication of major transitions

### **2. Enabled Features**

#### **âœ… Remove Silence** (Now Enabled)
- **What it does:** Automatically cuts out all detected silence segments
- **User benefit:** Shorter, tighter videos without dead air
- **Example:** 11-minute video with 87 silence segments â†’ Can save ~2-3 minutes

#### **âœ… Scene-Based Editing** (Future)
- **What it does:** Makes cuts at natural scene boundaries
- **User benefit:** Smoother transitions, professional-looking edits

### **3. Disabled Features (Without Analysis)**

#### **âŒ Remove Silence** (Disabled)
- Shows warning: "Run analysis first to enable silence removal"
- Checkbox is grayed out
- Tooltip explains why it's disabled

---

## ðŸ“Š What Users See

### **Before Analysis:**
```
[Analysis] Not started [Analyze Button]
```

### **After Analysis:**
```
[Analysis] Complete [Done Badge]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“Š Analysis Insights                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â±ï¸  Silence Detected                â”‚
â”‚     87 segments                     â”‚
â”‚     2m 15s total (15.3%)            â”‚
â”‚                                     â”‚
â”‚ ðŸŽ¬ Scene Changes                    â”‚
â”‚     3 cuts                          â”‚
â”‚     Major visual transitions        â”‚
â”‚                                     â”‚
â”‚ ðŸ’¡ Tip: Enable "Remove Silence" to  â”‚
â”‚    automatically cut out 87 silence â”‚
â”‚    gaps and save 2m 15s of time.   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[Edit Options]
â˜‘ï¸ Remove Silence âœ… (now enabled)
â˜ Jump Cuts (needs transcript)
â˜ Auto Captions (needs transcript)
```

---

## ðŸŽ¨ UI Changes Made

1. **Analysis Insights Card:**
   - Shows when analysis is complete
   - Displays silence count, total time, percentage
   - Shows scene change count
   - Includes helpful tip about using the data

2. **Feature Enablement:**
   - "Remove Silence" checkbox disabled if no analysis
   - Shows "(needs analysis)" tooltip
   - Warning message explains what's needed

3. **Status Indicators:**
   - "Analysis" button shows "Done" badge when complete
   - Clear visual feedback on what's available

---

## ðŸ’¡ Realistic Textual Insights (Simple, Not AI-Generated)

**What we show (simple stats):**
- âœ… Number of silence segments
- âœ… Total silence duration
- âœ… Silence percentage
- âœ… Number of scene changes
- âœ… Actionable tip (e.g., "Enable Remove Silence to save X time")

**What we DON'T show (too complex for MVP):**
- âŒ AI-generated recommendations ("Your video has too many pauses")
- âŒ Sentiment analysis ("This section is boring")
- âŒ Retention predictions ("Viewers drop off here")
- âŒ Complex insights requiring LLM calls

**Why?**
- Simple stats are fast and reliable
- No API costs
- No additional processing time
- Clear, actionable information

---

## ðŸš€ User Flow

1. **User uploads video** â†’ Video is ready
2. **User clicks "Analyze"** â†’ Analysis runs (1-3 minutes)
3. **Analysis completes** â†’ Insights card appears
4. **User sees:**
   - "87 silence segments detected"
   - "2m 15s of silence (15.3%)"
   - "Enable Remove Silence to save time"
5. **User enables "Remove Silence"** â†’ Creates edit job
6. **Result:** Shorter, tighter video

---

## ðŸ“ˆ Value Summary

**For Users:**
- **Clear understanding** of what analysis found
- **Actionable insights** (not just data)
- **Visual feedback** on what features are available
- **Time savings** (know how much silence can be removed)

**For Us:**
- **Simple implementation** (no complex AI)
- **Fast performance** (just parsing existing data)
- **Clear UX** (users know what to do next)
- **Low maintenance** (no external APIs)

---

## ðŸŽ¯ Next Steps (Future Enhancements)

If we have more time later:
1. **Visual timeline** showing silence segments
2. **Scene change previews** (thumbnails at cut points)
3. **Smart recommendations** ("This video has 30% silence - consider removing it")
4. **Comparison view** (before/after duration estimates)

But for MVP: **Simple stats + actionable tips = perfect!**

